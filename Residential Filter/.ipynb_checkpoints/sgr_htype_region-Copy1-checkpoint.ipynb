{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab4a5583-d187-4680-a1c1-441ab885e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e8577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broad_filter(res_cases):\n",
    "    # filter out cases with irrelevant type codes\n",
    "    types = ['PL_MINSP', 'PL_SSP_SM', 'PL_SSM_SM2', 'PL_CPAA', 'PL_MINPP', 'PL_MAJSP', 'PL_MAJSUP', 'PL_PPA', 'PL_MAJPP']\n",
    "    filter_cases_type = res_cases[res_cases['A_TYPE'].isin(types)]\n",
    "\n",
    "    # filter out cases with out of date status\n",
    "    status = res_cases['A_STATUS'].unique()\n",
    "    status = status[~np.isin(status, ['WITH', 'VOID','DEN','DISAP','EXP'])]\n",
    "    filter_cases_status = filter_cases_type[filter_cases_type['A_STATUS'].isin(status)]\n",
    "\n",
    "    # keep entries with keywords\n",
    "    keywords = ['home', 'family', 'residen', 'mixed', 'mized', 'duplex', 'apartment', ' housing', 'condo', 'dwelling', 'tenant', 'affordable', 'units', 'townhouse']\n",
    "    pattern = '|'.join(keywords)\n",
    "    filtered_in = filter_cases_status[filter_cases_status['A_DESCRIPT'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "    # remove entries with certain words\n",
    "    keywords_avoid = ['expand','storage']\n",
    "    pattern_avoid = '|'.join(keywords_avoid)\n",
    "    filtered_words = filtered_in[~filtered_in['A_DESCRIPT'].str.contains(pattern_avoid, case=False, na=False)]\n",
    "\n",
    "    # filter out entries that were last updated over 5 years ago\n",
    "    filtered_words = filtered_words.copy()\n",
    "    filtered_words['A_STATUS_D'] = pd.to_datetime(filtered_words['A_STATUS_D'])\n",
    "    filtered_final = filtered_words[filtered_words['A_STATUS_D'].dt.year>=2020]\n",
    "\n",
    "    return filtered_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45613bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_regex(term):\n",
    "    # makes it so string returns a match whether a term has spaces, dashes, both, or neither\n",
    "    return re.sub(r'[-\\s]+', r'\\\\s*-?\\\\s*', term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98718ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_units(description):\n",
    "    # remove square footage references\n",
    "    description = re.sub(\n",
    "        r'(\\d+|\\d{1,3}(,\\d{3})*)(\\s+[A-Za-z-]+){0,2}?\\s*(SF|square feet|sq\\.?\\s*ft\\.?|sqft)',\n",
    "        '', description, flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # map variations to standardized types\n",
    "    term_map = {\n",
    "        \"home\": \"home\", \"homes\": \"home\", \"house\": \"home\", \"houses\": \"home\",\n",
    "        \"duplex\": \"duplex\", \"duplexes\": \"duplex\",\n",
    "        \"condo\": \"condo\", \"condominium\": \"condo\", \"condominiums\": \"condo\", \"condos\": \"condo\", \n",
    "        \"apartment\": \"apartment\", \"apartments\": \"apartment\",\n",
    "        \"townhome\": \"townhouse\", \"townhomes\": \"townhouse\",\n",
    "        \"townhouse\": \"townhouse\", \"townhouses\": \"townhouse\",\n",
    "        \"town home\": \"townhouse\", \"town homes\": \"townhouse\",\n",
    "        \"town house\": \"townhouse\", \"town houses\": \"townhouse\",\n",
    "        \"multifamily\": \"multifamily\", \"multi-family\": \"multifamily\", \n",
    "        \"multi - family\": \"multifamily\", \"multi family\": \"multifamily\",\n",
    "        \"mutifamily\": \"multifamily\", \"MF\": \"multifamily\",\n",
    "        \"single family\": \"single family\", \"single-family\": \"single family\", \n",
    "        \"single - family\": \"single family\", \"s-f\": \"single family\", \"s - f\": \"single family\", \"s f\": \"single family\"\n",
    "    }\n",
    "\n",
    "    modifiers = [\"attached\", \"detached\"]\n",
    "    suffixes = [\"units\", \"lots\", \"homes\", \"houses\"]\n",
    "\n",
    "    housing_pattern = \"|\".join([normalize_for_regex(term) for term in term_map])\n",
    "    modifier_pattern = \"|\".join(modifiers)\n",
    "    suffix_pattern = \"|\".join(suffixes)\n",
    "\n",
    "    # extended match pattern to support both \"qty before type\" and \"type before qty\"\n",
    "    match_pattern = rf'''\n",
    "    (?:\n",
    "        # Qty before type\n",
    "        (?P<qty>\\(?\\d{{1,4}}\\)?)\n",
    "        (?:\\s*[-+&/]?\\s*)?\n",
    "        (?:({modifier_pattern})\\s*){{0,2}}?\n",
    "        (?:\\w+\\s*){{0,4}}?\n",
    "        (?P<type>{housing_pattern})\n",
    "        (?:\\s+({modifier_pattern}))?\n",
    "        (?:\\s+(?P<suffix>{suffix_pattern}))?\n",
    "\n",
    "    |\n",
    "        # Type before qty\n",
    "        (?P<type2>{housing_pattern})\n",
    "        (?:\\s+({modifier_pattern}))?\n",
    "        (?:\\s*[-+&/]?\\s*)?\n",
    "        (?:\\w+\\s*){{0,4}}?\n",
    "        (?P<qty2>\\(?\\d{{1,4}}\\)?)\n",
    "        (?:\\s+(?P<suffix2>{suffix_pattern}))?\n",
    "\n",
    "    |\n",
    "        # Type with quantity in parentheses\n",
    "        (?P<type3>{housing_pattern})\n",
    "        (?:\\s+\\w+){{0,4}}?\n",
    "        \\(\\s*(?P<qty3>\\d{{1,4}})\\s+(?P<suffix3>{suffix_pattern})\\s*\\)\n",
    "    )\n",
    "'''\n",
    "\n",
    "    matches = re.finditer(match_pattern, description, flags=re.IGNORECASE | re.VERBOSE)\n",
    "    \n",
    "    result = []\n",
    "    for match in matches:\n",
    "        qty = match.group(\"qty\") or match.group(\"qty2\")\n",
    "        raw_type = match.group(\"type\") or match.group(\"type2\")\n",
    "        raw_mod = match.group(2)  # first modifier (position varies)\n",
    "        raw_suffix = match.group(\"suffix\") or match.group(\"suffix2\")\n",
    "\n",
    "        if not qty or not raw_type:\n",
    "            continue  # skip malformed matches\n",
    "\n",
    "        # normalize type\n",
    "        norm_key = re.sub(r'[-\\s]+', ' ', raw_type.lower()).strip()\n",
    "        normalized_type = term_map.get(norm_key, norm_key)\n",
    "\n",
    "        result.append((\n",
    "            int(qty.strip(\"()\")),\n",
    "            raw_mod.lower() if raw_mod else None,\n",
    "            normalized_type,\n",
    "            raw_suffix.lower() if raw_suffix else None\n",
    "        ))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7fa7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_types(match_results):\n",
    "    housing_types = ['sf_detached', 'sf_attached', 'duplex/triplex', 'multifamily', 'condo']\n",
    "    housing_type_dict = {\n",
    "        'townhouse': 'sf_attached',\n",
    "        'home': 'sf_detached', 'single family': 'sf_detached',\n",
    "        'duplex': 'duplex/triplex',\n",
    "        'apartment': 'multifamily', 'multifamily': 'multifamily',\n",
    "        'condo': 'condo'\n",
    "    }\n",
    "\n",
    "    row_data = {h_type: 0 for h_type in housing_types}\n",
    "    for group in match_results:\n",
    "        quantity = group[0]\n",
    "        mod = group[1]\n",
    "        housing = group[2]\n",
    "\n",
    "        if housing == 'single family' and mod == 'attached':\n",
    "            row_data['sf_attached'] += quantity\n",
    "        elif housing in housing_type_dict:\n",
    "            row_data[housing_type_dict[housing]] += quantity\n",
    "\n",
    "    return pd.Series(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718c5fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input the name of the Durham developments shapefile:  durham_developments\n"
     ]
    }
   ],
   "source": [
    "durham_dev_filename = input('Please input the name of the Durham developments shapefile: ').strip()\n",
    "res_cases_raw = gpd.read_file(f'../data/{durham_dev_filename}')\n",
    "res_filtered = broad_filter(res_cases_raw)\n",
    "res_filtered['match_results'] = res_filtered['A_DESCRIPT'].apply(extract_units)\n",
    "housing_counts = res_filtered['match_results'].apply(fill_types)\n",
    "filtered_final = pd.concat([res_filtered, housing_counts], axis=1)\n",
    "filtered_final = filtered_final.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e43375-e7cb-4bea-aeea-56b4fadf304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from Data+_2025/data/enrollment_projections/sgr_table_region_2324_20240710.xlsx in Google Drive\n",
    "'''\n",
    "read in SGR data -- file paths: \n",
    "the current one is from 2024 July 10th, the file is already in data and is named sgr_tables_htype_reg.xlsx\n",
    "'''\n",
    "sgr_filename = input('Please enter the file name which includes the table of SGRs by housing type and region: ')\n",
    "sgr_data = gpd.read_file(f'../data/{sgr_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null values and shorten to only use relevant columns\n",
    "sgr_data = sgr_data.dropna()\n",
    "sgr_data.rename(columns={'sgr_dps_2324_all.1': 'sgr_dps_avg_k12'}, inplace=True) # because there might be a typo in the file?\n",
    "sgr_data = sgr_data[['housing_type','region','sgr_dps_avg_k12']]\n",
    "sgr_data['sgr_dps_avg_k12'] = sgr_data['sgr_dps_avg_k12'].round(4)\n",
    "sgr_data.set_index(['region', 'housing_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13de98f-1e3a-4250-8e81-fc112879f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "read in shapefile to get geometries for Durham County regions from Data+_2025/QGIS/DPS shapefiles from layers in Google Drive\n",
    "'''\n",
    "regions = gpd.read_file(r'../data/durham_regions.geojson')[['region', 'geometry']]\n",
    "regions = regions.to_crs('EPSG:4326')\n",
    "#read in geojson with residential developments\n",
    "# ''' \n",
    "# read in geojson with residential developments -- file paths: \n",
    "# Leah: /Users/leahwallihan/Durham_school_planning/DPS-Planning/GIS_files/resdev_cases.geojson'''\n",
    "# res_dev = gpd.read_file(r'/Users/kevan/OneDrive/Desktop/Data+/DPS-Planning/GIS_files/resdev_cases.geojson')\n",
    "# res_dev = res_dev.to_crs('EPSG:4326')\n",
    "# res_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3a132-de08-4dcf-b061-644d2319c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count number of students in each row\n",
    "def count_students(row): \n",
    "        \n",
    "    htype_map = {\n",
    "        'sf_detached': 'sf_detach',\n",
    "        'sf_attached': 'sf_attach',\n",
    "        'duplex/triplex': 'du_tri',\n",
    "        'multifamily': 'mf_apt',\n",
    "        'condo': 'condo'\n",
    "    }\n",
    "\n",
    "    region = row['region']\n",
    "\n",
    "    total = 0\n",
    "    for col_name, sgr_col in htype_map.items():\n",
    "        count = row.get(col_name, 0)\n",
    "\n",
    "        try:\n",
    "            multiplier = sgr_data.loc[(region, sgr_col), 'sgr_dps_avg_k12']\n",
    "        except KeyError:\n",
    "            multiplier = 0\n",
    "\n",
    "        total += count * multiplier\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ef292",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final['student_gen'] = filtered_final.apply(count_students, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504f427-8ffd-4394-bb94-c5e7dff523e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final[['region', 'sf_detached', 'sf_attached', 'multifamily', 'student_gen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c436aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_final.to_file('resdev_with_stu_proj.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final[\"student_gen\"].plot.hist(bins=20, edgecolor='black')\n",
    "\n",
    "plt.xlabel(\"Student_gen\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of student_gen values\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed835da9-543d-4176-8840-2b99ff685326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in planning unit shapefile \n",
    "pu = gpd.read_file('/Users/leahwallihan/Durham_school_planning/geospatial files/pu_shape.geojson')[['OBJECTID', 'geometry']]\n",
    "pu = pu.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50443e4d-1494-496a-8f33-d1d9982cc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "filtered_final['pu'] = filtered_final['pu'].fillna(0).astype(int)\n",
    "\n",
    "# get counts for each planning unit\n",
    "pu_gen = filtered_final.groupby('pu')['student_gen'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91305e9-c433-4b58-99f9-c6c31b6a3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu['student_gen'] = pu['OBJECTID'].map(pu_gen).fillna(0).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a56b4-dab0-4f99-b93c-4cc88e3712ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fix hs_full_geo\n",
    "pu = pu.set_index('OBJECTID')\n",
    "\n",
    "hs_full_geo = gpd.read_file('/Users/leahwallihan/Durham_school_planning/DPS-Planning/GIS_files/hs_full_geo.geojson')\n",
    "hs_full_geo = hs_full_geo.set_index('pu_2324_84')\n",
    "\n",
    "for i, row in pu.iterrows():\n",
    "    hs_full_geo.loc[i, 'student_gen'] = row['student_gen']\n",
    "\n",
    "# hs_full_geo.to_file('hs_full_geo.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa6fe8-4666-4580-83aa-db5cf43aae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.to_file('pu_gen.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe8d3c-2894-4368-b3c0-b4d2b1f73ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dev.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spatialdata]",
   "language": "python",
   "name": "conda-env-spatialdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
