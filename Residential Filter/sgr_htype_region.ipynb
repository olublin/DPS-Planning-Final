{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ab4a5583-d187-4680-a1c1-441ab885e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "38e8577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broad_filter(res_cases):\n",
    "    # filter out cases with irrelevant type codes\n",
    "    types = ['PL_MINSP', 'PL_SSP_SM', 'PL_SSM_SM2', 'PL_CPAA', 'PL_MINPP', 'PL_MAJSP', 'PL_MAJSUP', 'PL_PPA', 'PL_MAJPP']\n",
    "    filter_cases_type = res_cases[res_cases['A_TYPE'].isin(types)]\n",
    "\n",
    "    # filter out cases with out of date status\n",
    "    status = res_cases['A_STATUS'].unique()\n",
    "    status = status[~np.isin(status, ['WITH', 'VOID','DEN','DISAP','EXP'])]\n",
    "    filter_cases_status = filter_cases_type[filter_cases_type['A_STATUS'].isin(status)]\n",
    "\n",
    "    # keep entries with keywords\n",
    "    keywords = ['home', 'family', 'residen', 'mixed', 'mized', 'duplex', 'apartment', ' housing', 'condo', 'dwelling', 'tenant', 'affordable', 'units', 'townhouse']\n",
    "    pattern = '|'.join(keywords)\n",
    "    filtered_in = filter_cases_status[filter_cases_status['A_DESCRIPT'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "    # remove entries with certain words\n",
    "    keywords_avoid = ['expand','storage']\n",
    "    pattern_avoid = '|'.join(keywords_avoid)\n",
    "    filtered_words = filtered_in[~filtered_in['A_DESCRIPT'].str.contains(pattern_avoid, case=False, na=False)]\n",
    "\n",
    "    # filter out entries that were last updated over 5 years ago\n",
    "    filtered_words = filtered_words.copy()\n",
    "    filtered_words['A_STATUS_D'] = pd.to_datetime(filtered_words['A_STATUS_D'])\n",
    "    filtered_final = filtered_words[filtered_words['A_STATUS_D'].dt.year>=2020]\n",
    "\n",
    "    return filtered_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e45613bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_regex(term):\n",
    "    # makes it so string returns a match whether a term has spaces, dashes, both, or neither\n",
    "    return re.sub(r'[-\\s]+', r'\\\\s*-?\\\\s*', term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "98718ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_units(description):\n",
    "    # remove square footage references\n",
    "    description = re.sub(\n",
    "        r'(\\d+|\\d{1,3}(,\\d{3})*)(\\s+[A-Za-z-]+){0,2}?\\s*(SF|square feet|sq\\.?\\s*ft\\.?|sqft)',\n",
    "        '', description, flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # map variations to standardized types\n",
    "    term_map = {\n",
    "        \"home\": \"home\", \"homes\": \"home\", \"house\": \"home\", \"houses\": \"home\",\n",
    "        \"duplex\": \"duplex\", \"duplexes\": \"duplex\",\n",
    "        \"condo\": \"condo\", \"condominium\": \"condo\", \"condominiums\": \"condo\", \"condos\": \"condo\", \n",
    "        \"apartment\": \"apartment\", \"apartments\": \"apartment\",\n",
    "        \"townhome\": \"townhouse\", \"townhomes\": \"townhouse\",\n",
    "        \"townhouse\": \"townhouse\", \"townhouses\": \"townhouse\",\n",
    "        \"town home\": \"townhouse\", \"town homes\": \"townhouse\",\n",
    "        \"town house\": \"townhouse\", \"town houses\": \"townhouse\",\n",
    "        \"multifamily\": \"multifamily\", \"multi-family\": \"multifamily\", \n",
    "        \"multi - family\": \"multifamily\", \"multi family\": \"multifamily\",\n",
    "        \"mutifamily\": \"multifamily\", \"MF\": \"multifamily\",\n",
    "        \"single family\": \"single family\", \"single-family\": \"single family\", \n",
    "        \"single - family\": \"single family\", \"s-f\": \"single family\", \"s - f\": \"single family\", \"s f\": \"single family\"\n",
    "    }\n",
    "\n",
    "    modifiers = [\"attached\", \"detached\"]\n",
    "    suffixes = [\"units\", \"lots\", \"homes\", \"houses\"]\n",
    "\n",
    "    housing_pattern = \"|\".join([normalize_for_regex(term) for term in term_map])\n",
    "    modifier_pattern = \"|\".join(modifiers)\n",
    "    suffix_pattern = \"|\".join(suffixes)\n",
    "\n",
    "    # extended match pattern to support both \"qty before type\" and \"type before qty\"\n",
    "    match_pattern = rf'''\n",
    "    (?:\n",
    "        # Qty before type\n",
    "        (?P<qty>\\(?\\d{{1,4}}\\)?)\n",
    "        (?:\\s*[-+&/]?\\s*)?\n",
    "        (?:({modifier_pattern})\\s*){{0,2}}?\n",
    "        (?:\\w+\\s*){{0,4}}?\n",
    "        (?P<type>{housing_pattern})\n",
    "        (?:\\s+({modifier_pattern}))?\n",
    "        (?:\\s+(?P<suffix>{suffix_pattern}))?\n",
    "\n",
    "    |\n",
    "        # Type before qty\n",
    "        (?P<type2>{housing_pattern})\n",
    "        (?:\\s+({modifier_pattern}))?\n",
    "        (?:\\s*[-+&/]?\\s*)?\n",
    "        (?:\\w+\\s*){{0,4}}?\n",
    "        (?P<qty2>\\(?\\d{{1,4}}\\)?)\n",
    "        (?:\\s+(?P<suffix2>{suffix_pattern}))?\n",
    "\n",
    "    |\n",
    "        # Type with quantity in parentheses\n",
    "        (?P<type3>{housing_pattern})\n",
    "        (?:\\s+\\w+){{0,4}}?\n",
    "        \\(\\s*(?P<qty3>\\d{{1,4}})\\s+(?P<suffix3>{suffix_pattern})\\s*\\)\n",
    "    )\n",
    "'''\n",
    "\n",
    "    matches = re.finditer(match_pattern, description, flags=re.IGNORECASE | re.VERBOSE)\n",
    "    \n",
    "    result = []\n",
    "    for match in matches:\n",
    "        qty = match.group(\"qty\") or match.group(\"qty2\")\n",
    "        raw_type = match.group(\"type\") or match.group(\"type2\")\n",
    "        raw_mod = match.group(2)  # first modifier (position varies)\n",
    "        raw_suffix = match.group(\"suffix\") or match.group(\"suffix2\")\n",
    "\n",
    "        if not qty or not raw_type:\n",
    "            continue  # skip malformed matches\n",
    "\n",
    "        # normalize type\n",
    "        norm_key = re.sub(r'[-\\s]+', ' ', raw_type.lower()).strip()\n",
    "        normalized_type = term_map.get(norm_key, norm_key)\n",
    "\n",
    "        result.append((\n",
    "            int(qty.strip(\"()\")),\n",
    "            raw_mod.lower() if raw_mod else None,\n",
    "            normalized_type,\n",
    "            raw_suffix.lower() if raw_suffix else None\n",
    "        ))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a7fa7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_types(match_results):\n",
    "    housing_types = ['sf_detached', 'sf_attached', 'duplex/triplex', 'multifamily', 'condo']\n",
    "    housing_type_dict = {\n",
    "        'townhouse': 'sf_attached',\n",
    "        'home': 'sf_detached', 'single family': 'sf_detached',\n",
    "        'duplex': 'duplex/triplex',\n",
    "        'apartment': 'multifamily', 'multifamily': 'multifamily',\n",
    "        'condo': 'condo'\n",
    "    }\n",
    "\n",
    "    row_data = {h_type: 0 for h_type in housing_types}\n",
    "    for group in match_results:\n",
    "        quantity = group[0]\n",
    "        mod = group[1]\n",
    "        housing = group[2]\n",
    "\n",
    "        if housing == 'single family' and mod == 'attached':\n",
    "            row_data['sf_attached'] += quantity\n",
    "        elif housing in housing_type_dict:\n",
    "            row_data[housing_type_dict[housing]] += quantity\n",
    "\n",
    "    return pd.Series(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "718c5fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input the name of the Durham developments shapefile:  durham_developments\n"
     ]
    }
   ],
   "source": [
    "durham_dev_filename = input('Please input the name of the Durham developments shapefile: ').strip()\n",
    "res_cases_raw = gpd.read_file(f'../data/{durham_dev_filename}')\n",
    "res_filtered = broad_filter(res_cases_raw)\n",
    "res_filtered['match_results'] = res_filtered['A_DESCRIPT'].apply(extract_units)\n",
    "housing_counts = res_filtered['match_results'].apply(fill_types)\n",
    "filtered_final = pd.concat([res_filtered, housing_counts], axis=1)\n",
    "filtered_final = filtered_final.to_crs(epsg = 3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "25e43375-e7cb-4bea-aeea-56b4fadf304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the file name which includes the table of SGRs by housing type and region:  sgr_tables_htype_reg.csv\n"
     ]
    }
   ],
   "source": [
    "# read data from Data+_2025/data/enrollment_projections/sgr_table_region_2324_20240710.xlsx in Google Drive\n",
    "'''\n",
    "read in SGR data -- file paths: \n",
    "the current one is from 2024 July 10th, the file is already in data and is named sgr_tables_htype_reg.xlsx\n",
    "'''\n",
    "sgr_filename = input('Please enter the file name which includes the table of SGRs by housing type and region: ')\n",
    "sgr_data = gpd.read_file(f'../data/{sgr_filename}')\n",
    "sgr_data = sgr_data[sgr_data['region']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4526c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null values and shorten to only use relevant columns\n",
    "sgr_data.rename(columns={'sgr_dps_2324_all.1': 'sgr_dps_avg_k12'}, inplace=True) # because there might be a typo in the file?\n",
    "sgr_data = sgr_data[['housing_type','region','sgr_dps_avg_k12']]\n",
    "sgr_data['sgr_dps_avg_k12'] = sgr_data['sgr_dps_avg_k12'].round(4)\n",
    "sgr_data.set_index(['region', 'housing_type'], inplace=True)\n",
    "sgr_data['sgr_dps_avg_k12'] = pd.to_numeric(sgr_data['sgr_dps_avg_k12'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c13de98f-1e3a-4250-8e81-fc112879f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "read in shapefile to get geometries for Durham County regions from Data+_2025/QGIS/DPS shapefiles from layers in Google Drive\n",
    "'''\n",
    "regions = gpd.read_file(r'../data/durham_regions.geojson')[['region', 'geometry']]\n",
    "regions = regions.to_crs(epsg = 3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fab8e678-e73d-489b-aeb8-f3f36e6afbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final = filtered_final.copy()\n",
    "for i,geometry in enumerate(regions['geometry']):\n",
    "    in_geometry = geometry.contains(filtered_final['geometry'])\n",
    "\n",
    "    region = regions.loc[i,'region']\n",
    "    filtered_final.loc[in_geometry,'region'] = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "06b3a132-de08-4dcf-b061-644d2319c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count number of students in each row\n",
    "def count_students(row): \n",
    "        \n",
    "    htype_map = {\n",
    "        'sf_detached': 'sf_detach',\n",
    "        'sf_attached': 'sf_attach',\n",
    "        'duplex/triplex': 'du_tri',\n",
    "        'multifamily': 'mf_apt',\n",
    "        'condo': 'condo'\n",
    "    }\n",
    "\n",
    "    region = row['region']\n",
    "\n",
    "    total = 0\n",
    "    for col_name, sgr_col in htype_map.items():\n",
    "        count = row.get(col_name, 0)\n",
    "\n",
    "        try:\n",
    "            multiplier = sgr_data.loc[(region, sgr_col), 'sgr_dps_avg_k12']\n",
    "        except KeyError:\n",
    "            multiplier = 0\n",
    "\n",
    "        total += count * multiplier\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c56ef292",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final['student_gen'] = filtered_final.apply(count_students, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a504f427-8ffd-4394-bb94-c5e7dff523e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>sf_detached</th>\n",
       "      <th>sf_attached</th>\n",
       "      <th>multifamily</th>\n",
       "      <th>student_gen</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>North</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.434526</td>\n",
       "      <td>POINT (-8.79e+06 4.31e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>East</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (-8.77e+06 4.29e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Central</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (-8.78e+06 4.3e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Central</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (-8.79e+06 4.3e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>East</td>\n",
       "      <td>248</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>56.746881</td>\n",
       "      <td>POINT (-8.78e+06 4.29e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (-8.79e+06 4.29e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21423</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (-8.79e+06 4.29e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21445</th>\n",
       "      <td>Southeast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>48.621816</td>\n",
       "      <td>POINT (-8.78e+06 4.28e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21446</th>\n",
       "      <td>East</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3.208275</td>\n",
       "      <td>POINT (-8.78e+06 4.3e+06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>69.505846</td>\n",
       "      <td>POINT (-8.79e+06 4.29e+06)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          region  sf_detached  sf_attached  multifamily  student_gen  \\\n",
       "90         North           50            0            0    13.434526   \n",
       "139         East            0            0            0     0.000000   \n",
       "224      Central            0            0            0     0.000000   \n",
       "242      Central            0            0            0     0.000000   \n",
       "265         East          248           37            0    56.746881   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "21416  Southwest            0            0            0     0.000000   \n",
       "21423  Southwest            0            0            0     0.000000   \n",
       "21445  Southeast            0            0          369    48.621816   \n",
       "21446       East            0           46            0     3.208275   \n",
       "21470  Southwest            0            0          371    69.505846   \n",
       "\n",
       "                         geometry  \n",
       "90     POINT (-8.79e+06 4.31e+06)  \n",
       "139    POINT (-8.77e+06 4.29e+06)  \n",
       "224     POINT (-8.78e+06 4.3e+06)  \n",
       "242     POINT (-8.79e+06 4.3e+06)  \n",
       "265    POINT (-8.78e+06 4.29e+06)  \n",
       "...                           ...  \n",
       "21416  POINT (-8.79e+06 4.29e+06)  \n",
       "21423  POINT (-8.79e+06 4.29e+06)  \n",
       "21445  POINT (-8.78e+06 4.28e+06)  \n",
       "21446   POINT (-8.78e+06 4.3e+06)  \n",
       "21470  POINT (-8.79e+06 4.29e+06)  \n",
       "\n",
       "[276 rows x 6 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_final[['region', 'sf_detached', 'sf_attached', 'multifamily', 'student_gen','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3a8a90c3-8066-4283-81b9-7ea0cd3fd490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input the geodataframe with all planning units:  pu_2324_SPLIT.geojson\n"
     ]
    }
   ],
   "source": [
    "#read in the planning units\n",
    "pu_filename = input('Please input the geodataframe with all planning units: ')\n",
    "dps_pu = gpd.read_file(f'../data/{pu_filename}').rename(columns={'pu_2324_848':'pu_2324_84'})\n",
    "dps_pu = dps_pu.to_crs(epsg = 3857).sort_values(by='pu_2324_84')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "29e52550-7980-419c-b9e6-cf1e8f3894c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final = filtered_final.copy()\n",
    "for i,geometry in enumerate(dps_pu['geometry']):\n",
    "    in_geometry = geometry.contains(filtered_final['geometry'])\n",
    "    pu = dps_pu.loc[i,'pu_2324_84']\n",
    "    filtered_final.loc[in_geometry,'pu_2324_84'] = pu\n",
    "filtered_final = filtered_final.groupby('pu_2324_84')['student_gen'].sum().round(0).astype(int)\n",
    "\n",
    "full_index = pd.Index(range(1, 851), dtype=float)\n",
    "filtered_final = filtered_final.reindex(full_index, fill_value=0)\n",
    "filtered_final.index.name = 'pu_2324_84'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e3c79560-03eb-4b42-b68f-9b4591d599a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the file name for the file with current enrollment by planning unit by year and grade:  current_enrollment.csv\n"
     ]
    }
   ],
   "source": [
    "#loading in the current enrollment for only the 2024-25 school year\n",
    "enrollment_filename = input('Please enter the file name for the file with current enrollment by planning unit by year and grade: ')\n",
    "current_enrollment = gpd.read_file(f'../data/{enrollment_filename}').rename(columns={'pu_2324_848':'pu_2324_84'})\n",
    "current_enrollment = current_enrollment[['pu_2324_84','grade','fall_year','basez']].replace('', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4cccafb7-cb0c-433d-b3e5-896267f8ca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you like to get the enrollment projections for elementary, middle, or high schools? Enter as es, ms, or hs:  hs\n"
     ]
    }
   ],
   "source": [
    "school_type = input('Would you like to get the enrollment projections for elementary, middle, or high schools? Enter as es, ms, or hs: ')\n",
    "\n",
    "if school_type == 'es':\n",
    "    grades = [0,1,2,3,4,5]\n",
    "elif school_type == 'ms':\n",
    "    grades = [6,7,8]\n",
    "elif school_type == 'hs':\n",
    "    grades = [9,10,11,12]\n",
    "\n",
    "current_enrollment['pu_2324_84'] = pd.to_numeric(current_enrollment['pu_2324_84'],errors ='coerce')\n",
    "current_enrollment['grade'] = pd.to_numeric(current_enrollment['grade'],errors ='coerce')\n",
    "current_enrollment['fall_year'] = pd.to_numeric(current_enrollment['fall_year'],errors ='coerce')\n",
    "current_enrollment['basez'] =  pd.to_numeric(current_enrollment['basez'],errors ='coerce')\n",
    "\n",
    "current_by_type = current_enrollment[\n",
    "    (current_enrollment['grade'].isin(grades)) &\n",
    "    (current_enrollment['fall_year'].isin([2022,2023,2024]))\n",
    "     ]\n",
    "\n",
    "averaged_by_type = current_by_type.groupby(['pu_2324_84','grade'],as_index=False).mean()\n",
    "averaged_by_type = averaged_by_type.groupby(['pu_2324_84'],as_index=False).sum().drop(columns=['grade','fall_year'])\n",
    "\n",
    "all_pus = pd.DataFrame({'pu_2324_84': range(1,852)})\n",
    "full_basez = all_pus.merge(averaged_by_type, on='pu_2324_84',how='left').fillna(0)\n",
    "\n",
    "full_basez.loc[773,'basez'] = full_basez.loc[773,'basez'] * 30.0/81.0\n",
    "full_basez.loc[850,'basez'] = full_basez.loc[773,'basez'] * 51.0/81.0\n",
    "full_basez[['basez']] = full_basez[['basez']].round(0).astype(int)\n",
    "#full_basez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "06e8da5e-c454-4f14-a347-c8bc1b6883ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pu_2324_84</th>\n",
       "      <th>Region</th>\n",
       "      <th>geometry</th>\n",
       "      <th>basez</th>\n",
       "      <th>student_gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>North</td>\n",
       "      <td>POLYGON ((-8.77e+06 4.33e+06, -8.77e+06 4.33e+...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>North</td>\n",
       "      <td>POLYGON ((-8.78e+06 4.31e+06, -8.78e+06 4.31e+...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>East</td>\n",
       "      <td>POLYGON ((-8.77e+06 4.29e+06, -8.77e+06 4.29e+...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>POLYGON ((-8.79e+06 4.29e+06, -8.79e+06 4.29e+...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>East</td>\n",
       "      <td>POLYGON ((-8.77e+06 4.3e+06, -8.77e+06 4.3e+06...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>846</td>\n",
       "      <td>North</td>\n",
       "      <td>POLYGON ((-8.79e+06 4.32e+06, -8.79e+06 4.32e+...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>847</td>\n",
       "      <td>North</td>\n",
       "      <td>POLYGON ((-8.79e+06 4.31e+06, -8.79e+06 4.31e+...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>848</td>\n",
       "      <td>North</td>\n",
       "      <td>POLYGON ((-8.78e+06 4.31e+06, -8.78e+06 4.31e+...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>849</td>\n",
       "      <td>North</td>\n",
       "      <td>POLYGON ((-8.79e+06 4.31e+06, -8.79e+06 4.31e+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>850</td>\n",
       "      <td>North</td>\n",
       "      <td>POLYGON ((-8.79e+06 4.31e+06, -8.79e+06 4.31e+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>851 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pu_2324_84     Region                                           geometry  \\\n",
       "0             1      North  POLYGON ((-8.77e+06 4.33e+06, -8.77e+06 4.33e+...   \n",
       "1             2      North  POLYGON ((-8.78e+06 4.31e+06, -8.78e+06 4.31e+...   \n",
       "2             3       East  POLYGON ((-8.77e+06 4.29e+06, -8.77e+06 4.29e+...   \n",
       "3             4  Southwest  POLYGON ((-8.79e+06 4.29e+06, -8.79e+06 4.29e+...   \n",
       "4             5       East  POLYGON ((-8.77e+06 4.3e+06, -8.77e+06 4.3e+06...   \n",
       "..          ...        ...                                                ...   \n",
       "846         846      North  POLYGON ((-8.79e+06 4.32e+06, -8.79e+06 4.32e+...   \n",
       "847         847      North  POLYGON ((-8.79e+06 4.31e+06, -8.79e+06 4.31e+...   \n",
       "848         848      North  POLYGON ((-8.78e+06 4.31e+06, -8.78e+06 4.31e+...   \n",
       "849         849      North  POLYGON ((-8.79e+06 4.31e+06, -8.79e+06 4.31e+...   \n",
       "850         850      North  POLYGON ((-8.79e+06 4.31e+06, -8.79e+06 4.31e+...   \n",
       "\n",
       "     basez  student_gen  \n",
       "0        6            0  \n",
       "1       10            0  \n",
       "2        3            0  \n",
       "3        7            0  \n",
       "4        4            0  \n",
       "..     ...          ...  \n",
       "846      1            0  \n",
       "847      2            0  \n",
       "848     17            0  \n",
       "849      0            0  \n",
       "850      0            0  \n",
       "\n",
       "[851 rows x 5 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_geo = dps_pu.merge(full_basez, on = 'pu_2324_84')[['pu_2324_84'\"\",'Region','geometry','basez']]\n",
    "full_geo = full_geo.merge(filtered_final,on='pu_2324_84')\n",
    "full_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b7eeb126-a183-42fc-8ef3-5b496cee7635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7424"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_geo['basez'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4c4ce-7d7e-4fd3-ad6f-c3d78e4504bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spatialdata]",
   "language": "python",
   "name": "conda-env-spatialdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
